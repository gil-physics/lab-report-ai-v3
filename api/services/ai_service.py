import os
import google.generativeai as genai
import re


async def generate_ai_content(exp_name, analysis, template_id, template_content=None):
    # Load API key at runtime, not at import time
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        return "AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‚´ìš©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # Configure Gemini API with the loaded key
    genai.configure(api_key=GOOGLE_API_KEY)
    
    try:
        model = genai.GenerativeModel('gemini-3-flash-preview')
        
        # Build prompt using template if available
        template_context = ""
        if template_content:
            template_context = f"\n[ì°¸ê³ í•  ë³´ê³ ì„œ í…œí”Œë¦¿ êµ¬ì¡°]\n{template_content}\n"

        # ğŸ§  AI í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (ë°ì´í„° ì£¼ì…): í™˜ê° ë°©ì§€ë¥¼ ìœ„í•´ ëª…í™•í•œ ìˆ˜ì¹˜ ì œê³µ
        params_info = []
        if 'params' in analysis:
            p_vals = analysis.get('params', [])
            p_errs = analysis.get('standard_errors', [0.0] * len(p_vals))
            p_names = ['a', 'b', 'c', 'd', 'e']
            for i, (v, e) in enumerate(zip(p_vals, p_errs)):
                n = p_names[i] if i < len(p_names) else f"p{i}"
                params_info.append(f"{n} = {v:.4f} (Â±{e:.4f})")
        
        params_text = f"ì£¼ìš” íŒŒë¼ë¯¸í„° ìƒì„¸ ê°’: {', '.join(params_info)}" if params_info else ""

        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•™êµ ë¬¼ë¦¬í•™ ì‹¤í—˜ ì¡°êµ(TA)ì´ì ì „ë¬¸ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì•„ë˜ ì‹¤í—˜ ë°ì´í„°ì™€ ì œê³µëœ í…œí”Œë¦¿ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ  ë³´ê³ ì„œì˜ 'ê²°ê³¼ ë¶„ì„ ë° í† ì˜' ì„¹ì…˜ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        {template_context}
        
        [ì‹¤í—˜ ë°ì´í„° ì •ë³´]
        ì‹¤í—˜ ì£¼ì œ: {exp_name}
        ì ìš©ëœ ë¬¼ë¦¬ ì´ë¡ : {template_id if template_id != 'none' else 'ê¸°ë³¸ ë¬¼ë¦¬í•™ ë²•ì¹™'}
        íšŒê·€ ëª¨ë¸: {analysis.get('model')}
        ë„ì¶œëœ ìˆ˜ì‹: {analysis.get('equation')}
        ê²°ì •ê³„ìˆ˜ (RÂ²): {analysis.get('r_squared', 0):.4f}
        {params_text}

        [ì‘ì„± ê°€ì´ë“œë¼ì¸]
        1. **ìˆ˜ì‹ í‘œí˜„ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”)**: 
           - **ë¬¸ì¥ ì¤‘ê°„ ìˆ˜ì‹($)**: ë³€ìˆ˜ë‚˜ ê°„ë‹¨í•œ ì‹ì€ $ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. (ì˜ˆ: $F=ma$)
           - **ë…ë¦½ëœ ìˆ˜ì‹($$)**: ë³µì¡í•œ ìˆ˜ì‹ì€ ë°˜ë“œì‹œ **ì•ë’¤ë¡œ ì¤„ë°”ê¿ˆ(Enter)**ì„ í•˜ì—¬ ë…ë¦½ëœ ì¤„ì— ì‘ì„±í•´ì•¼ë§Œ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.
             (ì˜ëª»ëœ ì˜ˆ: ë”°ë¼ì„œ ì‹ì€ $$ E=mc^2 $$ ì´ë‹¤.)
             (ì˜¬ë°”ë¥¸ ì˜ˆ:
              ë”°ë¼ì„œ ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
              
              $$ E=mc^2 $$
              
              ì´ ê²°ê³¼ëŠ”...)
        2. **ë°ì´í„° ì •ë°€ë„ í‰ê°€**: íŒŒë¼ë¯¸í„°ì˜ í‘œì¤€ì˜¤ì°¨(Standard Error)ì™€ RÂ² ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤í—˜ì˜ ì •ë°€ë„ì™€ ë¶ˆí™•ì‹¤ì„±ì„ í‰ê°€í•˜ì„¸ìš”. ì˜¤ì°¨ê°€ ì‘ìœ¼ë©´ ì‹¤í—˜ì˜ ìˆ™ë ¨ë„ë‚˜ ì¥ë¹„ì˜ ì •í™•ì„±ì„ ì¹­ì°¬í•˜ê³ , í¬ë©´ êµ¬ì²´ì ì¸ ê°œì„ ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
        3. **í…œí”Œë¦¿ ì¤€ìˆ˜**: ì œê³µëœ í…œí”Œë¦¿ì— '[LLM ì‘ì„±]' ë˜ëŠ” '{{ë³€ìˆ˜}}'ë¼ê³  í‘œì‹œëœ ë¶€ë¶„ì˜ ë‚´ìš©ì„ í•™ìˆ ì ì¸ ë¬¸ì²´ë¡œ ì±„ì›Œë„£ìœ¼ì„¸ìš”.
        4. **ì˜¤ì°¨ ì›ì¸ ë¶„ì„**: RÂ² ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤í—˜ì˜ ì •ë°€ë„ë¥¼ í‰ê°€í•˜ê³ , ì‹¤ì œ ë¬¼ë¦¬ì  ì œì•½(ê³µê¸°ì €í•­, ë§ˆì°° ë“±)ì— ë”°ë¥¸ ì˜¤ì°¨ ì›ì¸ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
        5. **ê°€ë…ì„±**: ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ë¶ˆë › í¬ì¸íŠ¸(-)ì™€ êµµì€ ê¸€ì”¨(**)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ì¡°í•˜ì„¸ìš”.

        [í•œê¸€/LaTeX ì¶œë ¥ ê·œì¹™]
        - **ìˆ˜ì‹($)**: ìˆ˜ì‹ ê¸°í˜¸($)ëŠ” ì•ë’¤ ê¸€ìì™€ í•œ ì¹¸ ë„ì–´ì„œ ì‘ì„±í•˜ì„¸ìš”. (ì˜ˆ: "ê²°ê³¼ëŠ” $E=mc^2$ ì…ë‹ˆë‹¤")
        - **ê°•ì¡°(**)**: ê°•ì¡°í•  ë‹¨ì–´ëŠ” ì•ë’¤ ê¸€ìì™€ ê³µë°± ì—†ì´ ë¶™ì—¬ì„œ ì‘ì„±í•˜ì„¸ìš”. (ì˜ˆ: "**ê²°ë¡ **ì€")

        [í†¤ ì•¤ ë§¤ë„ˆ]
        - ëª…í™•í•˜ê³  í•™êµ¬ì ì¸ 'í•˜ì‹­ì‹œì˜¤ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(Heading, Bold, List)ì„ ì ì ˆíˆ ì„ì–´ì„œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        response = await model.generate_content_async(prompt)
        
        # Check if response was blocked or has no text
        if not response.text:
            # Get detailed error information
            error_details = []
            if hasattr(response, 'prompt_feedback'):
                error_details.append(f"Prompt feedback: {response.prompt_feedback}")
            if hasattr(response, 'candidates') and response.candidates:
                for i, candidate in enumerate(response.candidates):
                    error_details.append(f"Candidate {i} finish_reason: {candidate.finish_reason}")
                    if hasattr(candidate, 'safety_ratings'):
                        error_details.append(f"Candidate {i} safety_ratings: {candidate.safety_ratings}")
            
            error_msg = "AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. " + " | ".join(error_details) if error_details else "AI ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return error_msg
        
        return response.text
    except Exception as e:
        return f"AI ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
