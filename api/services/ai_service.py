import os
import google.generativeai as genai
import re


async def generate_ai_content(exp_name, analysis, template_id, template_content=None):
    # Load API key at runtime, not at import time
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        return "AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‚´ìš©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # Configure Gemini API with the loaded key
    genai.configure(api_key=GOOGLE_API_KEY)
    
    try:
        model = genai.GenerativeModel('gemini-3-flash-preview')
        
        # Build prompt using template if available
        template_context = ""
        if template_content:
            template_context = f"\n[ì°¸ê³ í•  ë³´ê³ ì„œ í…œí”Œë¦¿ êµ¬ì¡°]\n{template_content}\n"

        # ğŸ§  AI í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (ë°ì´í„° ì£¼ì…): í™˜ê° ë°©ì§€ë¥¼ ìœ„í•´ ëª…í™•í•œ ìˆ˜ì¹˜ ì œê³µ
        params_info = []
        if 'params' in analysis:
            p_vals = analysis.get('params', [])
            p_errs = analysis.get('standard_errors', [0.0] * len(p_vals))
            p_names = ['a', 'b', 'c', 'd', 'e']
            for i, (v, e) in enumerate(zip(p_vals, p_errs)):
                n = p_names[i] if i < len(p_names) else f"p{i}"
                params_info.append(f"{n} = {v:.4f} (Â±{e:.4f})")
        
        params_text = f"ì£¼ìš” íŒŒë¼ë¯¸í„° ìƒì„¸ ê°’: {', '.join(params_info)}" if params_info else ""

        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•™êµ ë¬¼ë¦¬í•™ ì‹¤í—˜ ì¡°êµ(TA)ì´ì ì „ë¬¸ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì•„ë˜ ì‹¤í—˜ ë°ì´í„°ì™€ ì œê³µëœ í…œí”Œë¦¿ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ  ë³´ê³ ì„œì˜ 'ê²°ê³¼ ë¶„ì„ ë° í† ì˜' ì„¹ì…˜ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        {template_context}
        
        [ì‹¤í—˜ ë°ì´í„° ì •ë³´]
        ì‹¤í—˜ ì£¼ì œ: {exp_name}
        ì ìš©ëœ ë¬¼ë¦¬ ì´ë¡ : {template_id if template_id != 'none' else 'ê¸°ë³¸ ë¬¼ë¦¬í•™ ë²•ì¹™'}
        íšŒê·€ ëª¨ë¸: {analysis.get('model')}
        ë„ì¶œëœ ìˆ˜ì‹: {analysis.get('equation')}
        ê²°ì •ê³„ìˆ˜ (RÂ²): {analysis.get('r_squared', 0):.4f}
        {params_text}

        [ì‘ì„± ê°€ì´ë“œë¼ì¸]
        1. **ìˆ˜ì‹ í‘œí˜„ ê·œì¹™ (ë§¤ìš° ì¤‘ìš” - ë Œë”ë§ ì‹¤íŒ¨ ë°©ì§€)**: 
           - **ì™¸ë¶€ ê³µë°± í•„ìˆ˜**: ìˆ˜ì‹ ê¸°í˜¸($)ì™€ ì•ë’¤ ê¸€ì(í•œê¸€, ì˜ì–´, ìˆ«ìëŠ” ë¬¼ë¡  ê´„í˜¸ í¬í•¨) ì‚¬ì´ì—ëŠ” **ë°˜ë“œì‹œ ê³µë°±ì„ í•œ ì¹¸** ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.
             (ì˜ëª»ëœ ì˜ˆ: ($R^2$), $R^2$ëŠ”)
             (ì˜¬ë°”ë¥¸ ì˜ˆ: ( $R^2$ ), $R^2$ ëŠ”)
           - **ë‚´ë¶€ ê³µë°± ê¸ˆì§€**: ìˆ˜ì‹ ê¸°í˜¸($) ë°”ë¡œ ì•ˆìª½ì—ëŠ” ê³µë°±ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
             (ì˜ëª»ëœ ì˜ˆ: $ R^2 $, $ E=mc^2 $)
             (ì˜¬ë°”ë¥¸ ì˜ˆ: $R^2$, $E=mc^2$)
           - **ë…ë¦½ëœ ìˆ˜ì‹($$)**: ë³µì¡í•œ ìˆ˜ì‹ì€ ë°˜ë“œì‹œ **ì•ë’¤ë¡œ ë¹ˆ ì¤„(Enter)**ì„ ë‘ì–´ ë…ë¦½ëœ ì¤„ì— ì‘ì„±í•˜ì„¸ìš”.
             $$ E = mc^2 $$
        2. **ë°ì´í„° ì •ë°€ë„ í‰ê°€**: íŒŒë¼ë¯¸í„°ì˜ í‘œì¤€ì˜¤ì°¨(Standard Error)ì™€ RÂ² ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤í—˜ì˜ ì •ë°€ë„ì™€ ë¶ˆí™•ì‹¤ì„±ì„ í‰ê°€í•˜ì„¸ìš”.
        3. **í…œí”Œë¦¿ ì¤€ìˆ˜**: ì œê³µëœ í…œí”Œë¦¿ì˜ êµ¬ì¡°ë¥¼ ì¡´ì¤‘í•˜ê³  í•™ìˆ ì ì¸ ë¬¸ì²´ë¡œ ë‚´ìš©ì„ ì±„ìš°ì„¸ìš”.
        4. **ì˜¤ì°¨ ì›ì¸ ë¶„ì„**: ì‹¤ì œ ë¬¼ë¦¬ì  ì œì•½(ê³µê¸°ì €í•­, ë§ˆì°° ë“±)ì— ë”°ë¥¸ ì˜¤ì°¨ ì›ì¸ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
        5. **ê°€ë…ì„±**: ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ë¶ˆë › í¬ì¸íŠ¸(-)ì™€ êµµì€ ê¸€ì”¨(**)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ì¡°í•˜ì„¸ìš”.

        [í•œê¸€/LaTeX ì¶œë ¥ ì˜ˆì‹œ]
        - "ê²°ê³¼ëŠ” ( $R^2 = 0.99$ ) ë¡œ ë‚˜íƒ€ë‚¬ìœ¼ë©°, ì´ëŠ” ë§¤ìš° ì •í™•í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
        - "ë§ˆì°° ê³„ìˆ˜ $ \mu $ ì™€ ìˆ˜ì§ í•­ë ¥ $ F_N $ ì˜ ê´€ê³„ëŠ”..." (X) -> "ë§ˆì°° ê³„ìˆ˜ $\mu$ ì™€ ìˆ˜ì§ í•­ë ¥ $F_N$ ì˜ ê´€ê³„ëŠ”..." (O)

        [í†¤ ì•¤ ë§¤ë„ˆ]
        - ëª…í™•í•˜ê³  í•™êµ¬ì ì¸ 'í•˜ì‹­ì‹œì˜¤ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(Heading, Bold, List)ì„ ì ì ˆíˆ ì„ì–´ì„œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        response = await model.generate_content_async(prompt)
        
        # Check if response was blocked or has no text
        if not response.text:
            # Get detailed error information
            error_details = []
            if hasattr(response, 'prompt_feedback'):
                error_details.append(f"Prompt feedback: {response.prompt_feedback}")
            if hasattr(response, 'candidates') and response.candidates:
                for i, candidate in enumerate(response.candidates):
                    error_details.append(f"Candidate {i} finish_reason: {candidate.finish_reason}")
                    if hasattr(candidate, 'safety_ratings'):
                        error_details.append(f"Candidate {i} safety_ratings: {candidate.safety_ratings}")
            
            error_msg = "AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. " + " | ".join(error_details) if error_details else "AI ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return error_msg
        
        return response.text
    except Exception as e:
        return f"AI ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
