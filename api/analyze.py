"""
Easy-Lab-Plotter Analysis API
Vercel Serverless Function for Physics Lab Data Analysis

FastAPI ì—”ë“œí¬ì¸íŠ¸: POST /api/analyze
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import sys
import os
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime
from urllib.parse import quote
import matplotlib
matplotlib.use('Agg')  # Non-GUI backend for server
import matplotlib.pyplot as plt
import google.generativeai as genai
from dotenv import load_dotenv
import platform

# Load environment variables from .env.local
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env.local'))

# Configure Gemini API
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# Font configuration for Korean support in matplotlib
system_os = platform.system()
if system_os == "Windows":
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif system_os == "Darwin":
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False  # Fix minus sign tofu

def load_report_template(template_id):
    if not template_id or template_id == 'none':
        return None
    
    # Template folder: ../report_templates/
    base_dir = os.path.dirname(os.path.dirname(__file__))
    template_path = os.path.join(base_dir, 'report_templates', f"{template_id}_í…œí”Œë¦¿.md")
    
    if not os.path.exists(template_path):
        # Try alternate check without "_í…œí”Œë¦¿" just in case
        template_path_alt = os.path.join(base_dir, 'report_templates', f"{template_id}.md")
        if os.path.exists(template_path_alt):
            template_path = template_path_alt
        else:
            return None
            
    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # Find the starting point: "âš ï¸ **LLM ì‚¬ìš© ì•ˆë‚´**"
            usage_guide_marker = 'âš ï¸ **LLM ì‚¬ìš© ì•ˆë‚´**'
            if usage_guide_marker in content:
                parts = content.split(usage_guide_marker, 1)
                content = usage_guide_marker + parts[1]
            
            # If marker not found, still try to strip leading YAML if it exists
            elif content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    content = parts[2].strip()
                    
            return content
    except Exception as e:
        print(f"Error loading template {template_id}: {e}")
        return None



def enforce_spacing_rules(text):
    """
    ìµœì†Œí•œì˜ ê°€ë…ì„± ë³´ì •:
    ìˆ˜ì‹($) ì•ë’¤ì—ë§Œ ì•½ê°„ì˜ ê³µë°±ì„ ì£¼ì–´ ë Œë”ë§ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    """
    if not text:
        return text
    
    import re
    # $ ìˆ˜ì‹ ì•ë’¤ì— ê¸€ìê°€ ë¶™ì–´ìˆìœ¼ë©´ í•œ ì¹¸ ë” (AIê°€ ë†“ì³¤ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ìµœì†Œ ë³´ì •)
    text = re.sub(r'(?<=[^$\s])(\$+)', r' \1', text)
    text = re.sub(r'(\$+)(?=[^$\s])', r'\1 ', text)
    
    return text


# Define AI Content Generator Helper
async def generate_ai_content(exp_name, analysis, template_id, template_content=None, raw_data_summary=None):
    if not GOOGLE_API_KEY:
        return "AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‚´ìš©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        model = genai.GenerativeModel('gemini-3-flash-preview')
        
        # Build prompt using template if available
        template_context = ""
        if template_content:
            template_context = f"\n[ì°¸ê³ í•  ë³´ê³ ì„œ í…œí”Œë¦¿ êµ¬ì¡°]\n{template_content}\n"

        # ğŸ“Š ë°ì´í„° í†µê³„ ìš”ì•½ ì •ë³´ ìƒì„±
        data_desc = ""
        example_citation = ""
        if raw_data_summary:
            data_desc = f"""
            [ì‹¤í—˜ ë°ì´í„° í†µê³„ ìš”ì•½]
            - ë°ì´í„° ê°œìˆ˜: {raw_data_summary.get('count', 0)} ê°œ
            - Xê°’ ë²”ìœ„: {raw_data_summary.get('x_min', 0):.4f} ~ {raw_data_summary.get('x_max', 0):.4f}
            - Yê°’ ë²”ìœ„: {raw_data_summary.get('y_min', 0):.4f} ~ {raw_data_summary.get('y_max', 0):.4f}
            - Yê°’ í‰ê· : {raw_data_summary.get('y_mean', 0):.4f} (í‘œì¤€í¸ì°¨: {raw_data_summary.get('y_std', 0):.4f})
            """
            example_citation = f"ì˜ˆ: \"ì¸¡ì •ëœ Yê°’ì€ í‰ê·  {raw_data_summary.get('y_mean', 0):.2f}ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ {raw_data_summary.get('y_min', 0):.2f}ì—ì„œ {raw_data_summary.get('y_max', 0):.2f} ì‚¬ì´ì˜ ë²”ìœ„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\""

        # ğŸ§  AI í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (ë°ì´í„° ì£¼ì…): í™˜ê° ë°©ì§€ë¥¼ ìœ„í•´ ëª…í™•í•œ ìˆ˜ì¹˜ ì œê³µ
        params_info = []
        if 'params' in analysis:
            p_vals = analysis.get('params', [])
            p_errs = analysis.get('standard_errors', [0.0] * len(p_vals))
            p_names = ['a', 'b', 'c', 'd', 'e']
            for i, (v, e) in enumerate(zip(p_vals, p_errs)):
                n = p_names[i] if i < len(p_names) else f"p{i}"
                params_info.append(f"{n} = {v:.4f} (Â±{e:.4f})")
        
        params_text = f"ì£¼ìš” íŒŒë¼ë¯¸í„° ìƒì„¸ ê°’: {', '.join(params_info)}" if params_info else ""

        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•™êµ ë¬¼ë¦¬í•™ ì‹¤í—˜ ì¡°êµ(TA)ì´ì ì „ë¬¸ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì•„ë˜ **ì‹¤ì œ ì‹¤í—˜ ë°ì´í„° í†µê³„**ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œì˜ 'ê²°ê³¼ ë¶„ì„ ë° í† ì˜' ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”.
        {template_context}
        
        {data_desc}

        [ë¶„ì„ ê²°ê³¼ ì •ë³´]
        ì‹¤í—˜ ì£¼ì œ: {exp_name}
        ì ìš©ëœ ë¬¼ë¦¬ ì´ë¡ : {template_id if template_id != 'none' else 'ê¸°ë³¸ ë¬¼ë¦¬í•™ ë²•ì¹™'}
        íšŒê·€ ëª¨ë¸: {analysis.get('name', analysis.get('model', 'N/A'))}
        ë„ì¶œëœ ìˆ˜ì‹: {analysis.get('equation', 'N/A')}
        ê²°ì •ê³„ìˆ˜ (RÂ²): {analysis.get('r_squared', 0):.4f}
        {params_text}

        [ì‘ì„± ê°€ì´ë“œë¼ì¸]
        1. **êµ¬ì²´ì  ìˆ˜ì¹˜ ì¸ìš© (í•„ìˆ˜)**: ì¶”ìƒì ì¸ í‘œí˜„ ëŒ€ì‹  ìœ„ 'ì‹¤í—˜ ë°ì´í„° í†µê³„ ìš”ì•½'ì— ìˆëŠ” **êµ¬ì²´ì ì¸ ìˆ˜ì¹˜(ìµœëŒ€/ìµœì†Œ/í‰ê· /í‘œì¤€í¸ì°¨ ë“±)**ë¥¼ ë¬¸ì¥ì— ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”. 
           - {example_citation if example_citation else 'ë°ì´í„° ì •ë°€ë„ì™€ ì‹ ë¢°ì„±ì„ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤.'}
        2. **ìˆ˜ì‹ í‘œí˜„ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”)**: 
           - **ì™¸ë¶€ ê³µë°± í•„ìˆ˜**: ìˆ˜ì‹ ê¸°í˜¸($)ì™€ ì•ë’¤ ê¸€ì ì‚¬ì´ì—ëŠ” **ë°˜ë“œì‹œ ê³µë°±ì„ í•œ ì¹¸** ë‘ì„¸ìš”. (ì˜ˆ: ( $R^2$ ), ê°’ì€ $x$ ì´ë‹¤)
           - **ë‚´ë¶€ ê³µë°± ê¸ˆì§€**: ìˆ˜ì‹ ê¸°í˜¸($) ë°”ë¡œ ì•ˆìª½ì—ëŠ” ê³µë°±ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: $R^2$, $E=mc^2$)
           - **ë…ë¦½ëœ ìˆ˜ì‹($$)**: ë³µì¡í•œ ìˆ˜ì‹ì€ ì•ë’¤ë¡œ ë¹ˆ ì¤„ì„ ë‘ì–´ ë…ë¦½ëœ ì¤„ì— ì‘ì„±í•˜ì„¸ìš”.
        3. **ë°ì´í„° ì •ë°€ë„ í‰ê°€**: í‘œì¤€ì˜¤ì°¨ì™€ RÂ² ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤í—˜ì˜ ì •ë°€ë„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
        4. **ì˜¤ì°¨ ì›ì¸ ë¶„ì„**: ì‹¤ì œ ë¬¼ë¦¬ì  ì œì•½ì— ë”°ë¥¸ ì˜¤ì°¨ ì›ì¸ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
        5. **ê°€ë…ì„±**: ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ë¶ˆë › í¬ì¸íŠ¸(-)ì™€ êµµì€ ê¸€ì”¨(**)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ì¡°í•˜ì„¸ìš”.

        [í†¤ ì•¤ ë§¤ë„ˆ]
        - ì „ë¬¸ì ì´ê³  í•™êµ¬ì ì¸ 'í•˜ì‹­ì‹œì˜¤ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”.
        """
        
        response = await model.generate_content_async(prompt)
        # ğŸ›¡ï¸ 'Safety Filter' ì ìš©: AIê°€ ë„ì–´ì“°ê¸° ê·œì¹™ì„ ì–´ê²¨ë„ ì½”ë“œê°€ ìë™ìœ¼ë¡œ ê°•ì œ ë³´ì •
        return enforce_spacing_rules(response.text)
    except Exception as e:
        return f"AI ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# utils ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(__file__))

from utils.curve_fitting import smart_curve_fitting, equation_to_latex
from utils.physics_formulas import get_recommended_formulas
from utils.outlier_detection import remove_outliers
from services.plot_service import generate_plot_file, generate_residual_plot_file

app = FastAPI(
    title="Easy-Lab-Plotter Analysis API",
    version="2.0.0",
    description="Physics lab data regression analysis and formula recommendation"
)

# CORS ì„¤ì • (ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš© - í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œí•œ ê¶Œì¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/api/analyze")
async def analyze_get():
    """GET ìš”ì²­ ì²˜ë¦¬ (ì •ë³´ ì œê³µ)"""
    return {
        "message": "Analysis API is running",
        "version": "2.0.0",
        "usage": "Send POST request with data and options",
        "example": {
            "data": {
                "x": [0, 1, 2, 3, 4],
                "y": [0, 9.8, 19.6, 29.4, 39.2]
            },
            "options": {
                "remove_outliers": True,
                "manual_model": None
            }
        }
    }


@app.post("/api/analyze")
async def analyze(request: Request):
    """
    ë¬¼ë¦¬ ì‹¤í—˜ ë°ì´í„° íšŒê·€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
    
    Request Body:
    {
        "data": {"x": [...], "y": [...]},
        "options": {
            "remove_outliers": bool,
            "manual_model": str | null,
            "outlier_method": str (default: "iqr"),
            "outlier_multiplier": float (default: 1.5)
        }
    }
    
    Response:
    {
        "status": "success",
        "best_model": {...},
        "residuals": [...],
        "recommended_formulas": [...],
        "data_info": {...}
    }
    """
    try:
        body = await request.json()
        
        # ë°ì´í„° ì¶”ì¶œ
        data = body.get("data", {})
        options = body.get("options", {})
        
        x_data = np.array(data.get("x", []))
        y_data = np.array(data.get("y", []))
        
        # ë°ì´í„° ê²€ì¦
        if len(x_data) == 0 or len(y_data) == 0:
            return JSONResponse(
                status_code=400,
                content={"status": "error", "message": "Data cannot be empty"}
            )
        
        if len(x_data) != len(y_data):
            return JSONResponse(
                status_code=400,
                content={"status": "error", "message": "X and Y data must have the same length"}
            )
        
        original_count = len(x_data)
        outliers_removed = 0
        
        # ì´ìƒì¹˜ ì œê±°
        remove_outliers_flag = options.get("remove_outliers", False)
        if remove_outliers_flag and len(x_data) >= 4:
            # DataFrame ìƒì„±
            df_temp = pd.DataFrame({"x": x_data, "y": y_data})
            
            outlier_method = options.get("outlier_method", "iqr")
            outlier_multiplier = options.get("outlier_multiplier", 1.5)
            
            df_cleaned, outliers_removed = remove_outliers(
                df_temp, 
                "y", 
                method=outlier_method,
                multiplier=outlier_multiplier
            )
            
            x_data = df_cleaned["x"].values
            y_data = df_cleaned["y"].values
        
        # ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ ì²´í¬
        if len(x_data) < 2:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "Not enough data points after outlier removal (minimum 2 required)"
                }
            )
        
        # íšŒê·€ ë¶„ì„
        manual_model = options.get("manual_model", None)
        
        if manual_model:
            best_model = smart_curve_fitting(x_data, y_data, models_to_try=[manual_model])
        else:
            best_model = smart_curve_fitting(x_data, y_data)
        
        if not best_model:
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": "Failed to fit any model to the data"
                }
            )
        
        # ì”ì°¨ ê³„ì‚°
        y_pred = best_model['func'](x_data, *best_model['params'])
        residuals = (y_data - y_pred).tolist()
        
        # ê³µì‹ ì¶”ì²œ (DataFrame í•„ìš”)
        df_for_formulas = pd.DataFrame({"x": x_data, "y": y_data})
        recommended_formulas = get_recommended_formulas(df_for_formulas)
        
        # ê³µì‹ ì •ë³´ ê°„ì†Œí™” (ìƒìœ„ 5ê°œë§Œ)
        simplified_formulas = []
        for formula in recommended_formulas[:5]:
            simplified_formulas.append({
                "name": formula["name"],
                "description": formula["description"],
                "matched_columns": formula["matched_columns"],
                "formula": formula["formula"],
                "result_name": formula["result_name"]
            })
        
        # LaTeX ìˆ˜ì‹ ìƒì„±
        latex_equation = equation_to_latex(best_model['equation'], best_model['params'])
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "status": "success",
            "best_model": {
                "name": best_model["name"],
                "model_key": best_model["model_key"],
                "r_squared": float(best_model["r_squared"]),
                "adj_r_squared": float(best_model.get("adj_r_squared", best_model["r_squared"])),
                "aic": float(best_model.get("aic", 0)),
                "params": [float(p) for p in best_model["params"]],
                "standard_errors": [float(se) for se in best_model.get("standard_errors", [])], # Add standard errors
                "equation": best_model["equation"],
                "latex": latex_equation
            },
            "residuals": residuals,
            "recommended_formulas": simplified_formulas,
            "data_info": {
                "original_count": int(original_count),
                "used_count": int(len(x_data)),
                "outliers_removed": int(outliers_removed)
            }
        }
        
        # ë‹¤ë¥¸ ëª¨ë¸ ë¹„êµ ì •ë³´ (ìˆìœ¼ë©´ ì¶”ê°€)
        if "all_results" in best_model and len(best_model["all_results"]) > 1:
            alternative_models = []
            for result in best_model["all_results"][:5]:
                alternative_models.append({
                    "name": result["name"],
                    "model_key": result["model_key"],
                    "r_squared": float(result["r_squared"]),
                    "adj_r_squared": float(result.get("adj_r_squared", result["r_squared"])),
                    "aic": float(result.get("aic", 0))
                })
            response_data["alternative_models"] = alternative_models
        
        return JSONResponse(content=response_data)
    
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e),
                "type": type(e).__name__
            }
        )


# Health check endpoint
@app.get("/api/health")
async def health():
    """Health check endpoint for monitoring"""
    return {"status": "healthy", "service": "analysis"}


# Markdown Report Preparation endpoint
@app.post("/api/prepare-report-md")
async def prepare_report_md(request: Request):
    """
    ì—¬ëŸ¬ ë¶„ì„ í•­ëª©ì„ í•˜ë‚˜ì˜ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì´ˆì•ˆìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
    """
    try:
        body = await request.json()
        
        template = body.get('template', 'none')
        items = body.get('items', [])
        use_ai = body.get('use_ai', False)
        
        if not items:
            return JSONResponse(status_code=400, content={"status": "error", "message": "No analysis items provided"})

        md_content = ["# ë¬¼ë¦¬ ì‹¤í—˜ ë³´ê³ ì„œ\n"]
        
        if template and template != 'none':
            template_name = template.replace('_', ' ')
            md_content.append(f"## {template_name}\n")
        
        # Load template content
        template_content = load_report_template(template)
        
        # Theory Section (from template)
        if template_content:
            theory_part = template_content
            if "í† ì˜ ë° ê²°ë¡ " in template_content:
                theory_part = template_content.split("í† ì˜ ë° ê²°ë¡ ", 1)[0]
            elif "## ê²°ë¡ " in template_content:
                theory_part = template_content.split("## ê²°ë¡ ", 1)[0]
            
            if "1. ì‹¤í—˜ê²°ê³¼ë¶„ì„" in theory_part:
                theory_part = theory_part.split("1. ì‹¤í—˜ê²°ê³¼ë¶„ì„")[0]
            
            md_content.append(theory_part.strip())
            md_content.append("\n---\n")

        # Determine base URL for static files (plots)
        host = request.headers.get("host", "localhost:8000")
        protocol = "https" if request.headers.get("x-forwarded-proto") == "https" else "http"
        base_url = f"{protocol}://{host}"

        # Analysis Results Section
        md_content.append("## 1. ì‹¤í—˜ ê²°ê³¼ ë° ë¶„ì„\n")
        
        for idx, item in enumerate(items):
            exp_name = item.get('experiment_name', f'ì‹¤í—˜ {idx+1}')
            data = item.get('data', {})
            x_label = item.get('x_label', 'X')
            y_label = item.get('y_label', 'Y')
            
            # Regression Data (Raw)
            x_vals = np.array(data.get('x', []), dtype=float)
            y_vals = np.array(data.get('y', []), dtype=float)
            
            mask = ~np.isnan(x_vals) & ~np.isnan(y_vals)
            x_vals = x_vals[mask]
            y_vals = y_vals[mask]

            print(f"DEBUG [prepare-report-md]: Data count={len(x_vals)}, X={x_label}")

            if len(x_vals) < 2:
                continue

            # ğŸ› ï¸ ALWAYS use Python to recalculate analysis for the final report (Source of Truth)
            analysis = smart_curve_fitting(x_vals, y_vals)
            if not analysis:
                continue
                
            # LaTeX ìˆ˜ì‹ ìƒì„±
            latex_equation = equation_to_latex(analysis['equation'], analysis['params'])
            
            # Prediction for plotting
            y_pred_vals = analysis['func'](x_vals, *analysis['params'])
            residuals_vals = y_vals - y_pred_vals
            
            md_content.append(f"### 1.{idx+1}. {exp_name}\n")
            
            # Summary Table
            md_content.append("| í•­ëª© | ë‚´ìš© |")
            md_content.append("| :--- | :--- |")
            md_content.append(f"| ìµœì  ëª¨ë¸ | {analysis.get('name', 'N/A')} |")
            md_content.append(f"| íšŒê·€ ìˆ˜ì‹ | ${latex_equation}$ |")
            md_content.append(f"| ê²°ì •ê³„ìˆ˜ ($R^2$) | {analysis.get('r_squared', 0):.4f} |")
            
            # Parameters
            if 'params' in analysis and analysis['params']:
                p_vals = analysis['params']
                p_errs = analysis.get('standard_errors', [0.0] * len(p_vals))
                param_names = ['a', 'b', 'c', 'd', 'e']
                
                params_md = []
                for i, (val, err) in enumerate(zip(p_vals, p_errs)):
                    p_name = param_names[i] if i < len(param_names) else f"p{i}"
                    params_md.append(f"{p_name} = {val:.4f} (Â± {err:.4f})")
                
                md_content.append(f"| ì¶”ì • íŒŒë¼ë¯¸í„° | {', '.join(params_md)} |")
            
            md_content.append("\n")
            
            # ğŸ–¼ï¸ Generate Static Graph Files using Matplotlib (Quality over Speed)
            plot_filename = f"report_graph_{uuid.uuid4()}.png"
            res_filename = f"report_residual_{uuid.uuid4()}.png"
            
            # Directory setup
            plots_dir = os.path.join(os.path.dirname(__file__), "static", "plots")
            if not os.path.exists(plots_dir):
                os.makedirs(plots_dir)
            
            # Save files
            generate_plot_file(x_vals, y_vals, os.path.join(plots_dir, plot_filename), y_pred_vals, x_label, y_label, f"{exp_name} íšŒê·€ ë¶„ì„")
            generate_residual_plot_file(x_vals, residuals_vals, os.path.join(plots_dir, res_filename), x_label, y_label, f"{exp_name} ì”ì°¨ ë¶„ì„")
            
            # Markdown links
            md_content.append(f"![{exp_name} íšŒê·€ ë¶„ì„ ê·¸ë˜í”„]({base_url}/plots/{plot_filename})\n")
            md_content.append(f"![{exp_name} ì”ì°¨ ê·¸ë˜í”„]({base_url}/plots/{res_filename})\n")

            # Capture the first plot URL to return for context usage
            if 'first_plot_url' not in locals():
                first_plot_url = f"{base_url}/plots/{plot_filename}"
            
            # AI Discussion
            if use_ai:
                # ğŸ“Š ì›ë³¸ ë°ì´í„° í†µê³„ ê³„ì‚° ì¶”ê°€
                raw_data_summary = {
                    "count": int(len(x_vals)),
                    "x_min": float(np.min(x_vals)),
                    "x_max": float(np.max(x_vals)),
                    "y_min": float(np.min(y_vals)),
                    "y_max": float(np.max(y_vals)),
                    "y_mean": float(np.mean(y_vals)),
                    "y_std": float(np.std(y_vals))
                }

                md_content.append(f"#### ğŸ“Š AI ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ë° ê³ ì°° ({exp_name})\n")
                ai_content = await generate_ai_content(exp_name, analysis, template, template_content, raw_data_summary)
                md_content.append(ai_content)
                md_content.append("\n")

        # Footer Section (from template)
        if template_content:
            footer_part = ""
            if "í† ì˜ ë° ê²°ë¡ " in template_content:
                footer_part = "## 2. í† ì˜ ë° ê²°ë¡ \n" + template_content.split("í† ì˜ ë° ê²°ë¡ ", 1)[1]
            elif "## ê²°ë¡ " in template_content:
                footer_part = "## 2. ê²°ë¡ \n" + template_content.split("## ê²°ë¡ ", 1)[1]
            
            if footer_part:
                md_content.append("\n---\n")
                md_content.append(footer_part.strip())

        return JSONResponse(content={
            "status": "success",
            "markdown": "\n".join(md_content),
            "plot_url": locals().get('first_plot_url', None)
        })
        
    except Exception as e:
        print(f"Error preparing report MD: {str(e)}")
        return JSONResponse(status_code=500, content={"status": "error", "message": str(e)})



        
    except Exception as e:
        print(f"Error generating report: {str(e)}")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"Report generation failed: {str(e)}"}
        )


# Vercel handler (ASGI app)
# Vercelì´ ì´ ë³€ìˆ˜ë¥¼ ì°¾ì•„ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤
handler = app
